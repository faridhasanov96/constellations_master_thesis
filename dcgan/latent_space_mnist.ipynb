{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Db1D3tJT18O9"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CrAf_jG-18O-",
    "outputId": "56e50c35-bf26-4849-c0cc-472004a8731c"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G6HFuoKq18PB"
   },
   "source": [
    "Next, we load the pretrained weights for each network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "gen_state_dict = torch.load(\n",
    "    'best_gan_weights/mnist_gen_epoch_91.pth',\n",
    "    map_location=device,\n",
    ")\n",
    "d_state_dict = torch.load(\n",
    "    'best_gan_weights/mnist_dis_epoch_91.pth',\n",
    "    map_location=device,\n",
    ")\n",
    "c_state_dict = torch.load(\n",
    "    'best_gan_weights/classifier_mnist.pth',\n",
    "    map_location=device,\n",
    ")\n",
    "\n",
    "ngpu = 1\n",
    "nz = 100\n",
    "ngf = 64\n",
    "ndf = 64\n",
    "nc = 1\n",
    "\n",
    "generator = Generator(ngpu).to(device)\n",
    "generator.load_state_dict(gen_state_dict)\n",
    "\n",
    "discriminator = Discriminator(ngpu).to(device)\n",
    "discriminator.load_state_dict(d_state_dict)\n",
    "\n",
    "classifier = Network().to(device)\n",
    "classifier.load_state_dict(c_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zo0MEN__1D-9"
   },
   "outputs": [],
   "source": [
    "from constellation_noise import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "location = 'mnist/6.jpg'\n",
    "noise_dotted = constellation_create(location,15,1,0.003)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "import scipy.ndimage as ndi\n",
    "\n",
    "mass = mpimg.imread(location)\n",
    "\n",
    "def get_position(np_array):\n",
    "    return ndi.center_of_mass(np_array)\n",
    "\n",
    "get_position(mass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m62VxYzo6UqI",
    "outputId": "6a740419-a069-4c86-a09b-42b3b0c6f80c"
   },
   "outputs": [],
   "source": [
    "def pass_dots_loss(image_noise_dots, image):\n",
    "  noise_dots = stimuli_dots(image_noise_dots)\n",
    "  gray = drawing_figure(image)\n",
    "\n",
    "  d_img = points_on_image(gray,noise_dots,10)\n",
    "  loss_1 = len(d_img)/len(noise_dots)\n",
    "  return loss_1\n",
    "from tqdm import tqdm\n",
    "\n",
    "from math import atan2, cos, sin, sqrt, pi\n",
    "import numpy as np\n",
    "\n",
    "def get_angle(numpy_array):\n",
    "    _, bw = cv2.threshold(numpy_array, 50, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
    "\n",
    "    contours, _ = cv2.findContours(bw, cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)\n",
    "    needed_angle = 0\n",
    "    biggest_area = 0\n",
    "    for i, c in enumerate(contours):\n",
    "      area = cv2.contourArea(c)\n",
    "      if area > biggest_area:\n",
    "        biggest_area = area\n",
    "        rect = cv2.minAreaRect(c)\n",
    "        center = (int(rect[0][0]),int(rect[0][1])) \n",
    "        width = int(rect[1][0])\n",
    "        height = int(rect[1][1])\n",
    "        angle = int(rect[2])\n",
    "        if width < height:\n",
    "            angle = 90 - angle\n",
    "        else:\n",
    "            angle = -angle\n",
    "        needed_angle = angle\n",
    "    return needed_angle\n",
    "#get_angle(img_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def get_prediction(imgs, classifier):\n",
    "    return torch.max(classifier(imgs), 1).indices.cpu().numpy().reshape(150,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def denorm(img_tensors):\n",
    "    return img_tensors * 2 -1 \n",
    "def norm(img_tensors):\n",
    "    return (img_tensors+ 1)/2 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "imagess = glob.glob('mnist_together/*')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference_image_generator(immage,distance,times):\n",
    "\n",
    "    archive = SlidingBoundariesArchive(\n",
    "    dims = [200,60,6],\n",
    "    ranges = [(0,500),(0.1,0.6),(0,9)],  # boldness, pass_dots, class.\n",
    ")\n",
    "\n",
    "    emitters = [\n",
    "    ImprovementEmitter(\n",
    "        archive,\n",
    "        np.zeros(100),\n",
    "        0.1,\n",
    "        batch_size=30,\n",
    "    ) for _ in range(5)\n",
    "]\n",
    "\n",
    "    optimizer = Optimizer(archive, emitters)\n",
    "    #total_itrs = 200\n",
    "    flat_img_size = 64*64  # 28 * 28\n",
    "    start_time = time.time()\n",
    "    class_scores = []\n",
    "    values = []\n",
    "    images_through_training = []\n",
    "    noised = constellation_create(immage,distance,1,0.003)\n",
    "\n",
    "    total_itrs = times\n",
    "    for itr in range(1, total_itrs + 1):\n",
    "        rotation_angles = []\n",
    "        sols = optimizer.ask()\n",
    "        with torch.no_grad():\n",
    "            tensor_sols = torch.tensor(\n",
    "                sols,\n",
    "                dtype=torch.float32,\n",
    "                device=device,\n",
    "                    )\n",
    "            tensor_sols = tensor_sols.unsqueeze(-1).unsqueeze(-1)\n",
    "            generated_imgs = generator(tensor_sols)\n",
    "            classes = get_prediction(generated_imgs, classifier)\n",
    "            digit_realness_scores = discriminator(generated_imgs).detach().cpu().numpy()\n",
    "            normalized_imgs = (generated_imgs + 1.0) / 2.0\n",
    "\n",
    "            dot_loss_scores = []\n",
    "            for img in generated_imgs:\n",
    "              t = img[0].cpu().numpy()*255\n",
    "              t = t.astype('uint8')\n",
    "              score=pass_dots_loss(noised,t)\n",
    "              angle = get_angle(t)\n",
    "              dot_loss_scores.append(score)\n",
    "              rotation_angles.append([angle])\n",
    "            dot_loss_scores = np.array(dot_loss_scores,dtype = np.float32)\n",
    "\n",
    "            flattened_imgs = normalized_imgs.cpu().numpy().reshape((-1, flat_img_size))\n",
    "            boldness = np.count_nonzero(flattened_imgs >= 0.5,axis=1,keepdims=True)\n",
    "            rotations = np.array(rotation_angles)\n",
    "            objs = 0.9*digit_realness_scores + 0.1*dot_loss_scores \n",
    "            dot_loss_scores = dot_loss_scores.reshape(150,1)\n",
    "\n",
    "            bcs = np.concatenate([boldness,dot_loss_scores,classes], axis=1)\n",
    "        optimizer.tell(objs, bcs)\n",
    "        \n",
    "    new_archive = archive.as_pandas().sort_values(by=['objective'], ascending = False)\n",
    "    array = np.array(new_archive.iloc[0, 7:])\n",
    "    tensor_sols = torch.tensor(\n",
    "            array,\n",
    "            dtype=torch.float32,\n",
    "            device=device,\n",
    "        )\n",
    "    tensor_sols = tensor_sols.unsqueeze(-1).unsqueeze(-1).unsqueeze(0)\n",
    "\n",
    "    output = generator(tensor_sols)\n",
    "    \n",
    "    return noised,(output[0],new_archive.iloc[0,6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "imagess = glob.glob('mnist_together/*')\n",
    "\n",
    "noised_images = []\n",
    "top_image = []\n",
    "for img in tqdm(range(len(imagess))):\n",
    "    noised, tuple_image_score = inference_image_generator(imagess[img],15,35)\n",
    "    top_image.append(tuple_image_score)\n",
    "    noised_images.append(noised)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_drawn = []\n",
    "\n",
    "def drawing_figure(image):\n",
    "    gray = image \n",
    "    gray = cv2.resize(gray,(800,800))\n",
    "    th, threshed = cv2.threshold(gray, 40, 255,cv2.THRESH_BINARY)\n",
    "    cnts = cv2.findContours(threshed, cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)[-2]\n",
    "    sc =[]\n",
    "    for ind,c in enumerate(cnts):\n",
    "        area = cv2.contourArea(c)\n",
    "        #print(area)\n",
    "        if(area<25000): continue\n",
    "        sc.append(c.copy())\n",
    "    draw_img = np.zeros(gray.shape)\n",
    "    for s in sc:\n",
    "        for pt in s:\n",
    "            draw_img[pt[0][1],pt[0][0]] = 255\n",
    "    return draw_img, sc\n",
    "for i in range(len(top_image)-1):\n",
    "    noise_dotted_for_drawing = cv2.resize(noised_images[i], dsize=(800,800))\n",
    "    t = top_image[i][0][0].detach().cpu().numpy()*255\n",
    "    t = t.astype('uint8')\n",
    "    contoured_img, hh = drawing_figure(t) \n",
    "    #plt.imshow(contoured_img)\n",
    "    im2 = cv2.drawContours(noise_dotted_for_drawing, hh, -1, (255, 255, 255), 8)\n",
    "    im2 = torch.tensor(im2).unsqueeze(0)\n",
    "    #im2 = transform(im2)\n",
    "    imgs_drawn.append(im2)#im2 = cv2.resize(im2, dsize=(120,120))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figsize=(8, 5)\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "fig = plt.figure(figsize=figsize)\n",
    "img_grid1 = make_grid(imgs_drawn, nrow=10, padding=10,pad_value=255)\n",
    "ax = plt.imshow(np.transpose(img_grid1.detach().cpu().numpy(), (1, 2, 0)),cmap='gray')\n",
    "plt.axis('off')\n",
    "fig.savefig('drawn_gan.png', bbox_inches='tight', pad_inches=0)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "lsi_mnist.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
